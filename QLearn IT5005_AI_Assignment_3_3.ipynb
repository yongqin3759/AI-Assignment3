{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5fuj3bc-U6r"
      },
      "source": [
        "# Assignment 3 - Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jwA-q1B-U6u"
      },
      "source": [
        "## GridWorlds\n",
        "\n",
        "This assignment involves finding optimal policies for two grid worlds (CliffWalking and WindyGridWorld) using SARSA and Q learning. Details about WindyGridWorld (Example 6.5) and CliffWalking (Example 6.6) can be found in the following link.\n",
        "    \n",
        "    http://incompleteideas.net/book/RLbook2020.pdf\n",
        "\n",
        "\n",
        "You need gym (version 0.18) and numpy (version 1.20.1) for this assignment. The environment for both problems are provided. \n",
        "\n",
        "For Windy Grid World environemnt you also need the file 'WindyGridWorld.py'. \n",
        "\n",
        "### Task 1: Learning [5 Marks]\n",
        "\n",
        "You only need to write the codes for SARSA and Q-learning algorithms. Then do the learning in both 'CliffWalking' and 'Windy Grid World' environments. \n",
        "\n",
        "### Task 2: Analysis [5 Marks]   \n",
        "\n",
        "1. Calculate the average return across the episodes. It gives you a measure of the performance of the algorithm while learning.  \n",
        "\n",
        "2. Calculate the return after convergence. It gives you a measure of the performance after the learning is completed. \n",
        "\n",
        "3. What do you observe from these results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYhZ5Mfc-U6v"
      },
      "source": [
        "Install the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNcED6Wl-U6v",
        "outputId": "9e8ac628-0218-41e7-c38c-f6ae086217b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: gym==0.18 in c:\\tools\\anaconda3\\envs\\it5005\\lib\\site-packages (0.18.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in c:\\tools\\anaconda3\\envs\\it5005\\lib\\site-packages (from gym==0.18) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in c:\\users\\e0833561\\appdata\\roaming\\python\\python38\\site-packages (from gym==0.18) (1.20.1)\n",
            "Requirement already satisfied: scipy in c:\\tools\\anaconda3\\envs\\it5005\\lib\\site-packages (from gym==0.18) (1.9.3)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\tools\\anaconda3\\envs\\it5005\\lib\\site-packages (from gym==0.18) (1.6.0)\n",
            "Requirement already satisfied: Pillow<=7.2.0 in c:\\tools\\anaconda3\\envs\\it5005\\lib\\site-packages (from gym==0.18) (7.2.0)\n",
            "Requirement already satisfied: future in c:\\tools\\anaconda3\\envs\\it5005\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.18) (0.18.2)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: numpy==1.20.1 in c:\\users\\e0833561\\appdata\\roaming\\python\\python38\\site-packages (1.20.1)\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: tqdm in c:\\users\\e0833561\\appdata\\roaming\\python\\python38\\site-packages (4.64.1)\n",
            "Requirement already satisfied: colorama in c:\\tools\\anaconda3\\envs\\it5005\\lib\\site-packages (from tqdm) (0.4.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install gym==0.18\n",
        "!pip install numpy==1.20.1\n",
        "!pip install tqdm "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYeXJEip-U6w"
      },
      "source": [
        "# Task 1: Learning\n",
        "## Task 1a: Learning in CliffWalking Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLFhiA86-U6w"
      },
      "source": [
        "### Environment for CliffWalking\n",
        "\n",
        "The board is a 4x12 matrix, with (using NumPy matrix indexing):\n",
        "    [3, 0] as the start at bottom-left\n",
        "    [3, 11] as the goal at bottom-right\n",
        "    [3, 1..10] as the cliff at bottom-center\n",
        "\n",
        "Each time step incurs -1 reward, and stepping into the cliff incurs -100 reward\n",
        "and a reset to the start. If an action would take you off the grid, you remain in the previous state.\n",
        "An episode terminates when the agent reaches the goal.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51k5bDhU-U6w",
        "outputId": "a0b21e3c-5e7c-4a25-efd7-d0918851474c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "x  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "import numpy as np\n",
        "from tqdm import tqdm \n",
        "\n",
        "env = gym.make('CliffWalking-v0') # Create the environment #render_mode=\"human\"  human, ansi, \n",
        "env.reset() # reset environment to a new, random state\n",
        "env.render() # Renders the environment for visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4A_vwCj-U6x"
      },
      "source": [
        "Here _x_ is the location of the agent, *o* are possible places to go to, *C* is the cliff, and *T* is the target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBsK1JJx-U6x",
        "outputId": "7954e644-f544-442c-e64b-2b39ca33c824"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of actions:  4\n",
            "Number of states:  48\n"
          ]
        }
      ],
      "source": [
        "num_actions = env.action_space.n \n",
        "num_states = env.observation_space.n \n",
        "\n",
        "print(\"Number of actions: \", num_actions)\n",
        "print(\"Number of states: \", num_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSzMUK7Z-U6x",
        "outputId": "67c28bf8-90fa-4ef6-e435-0630a40e176e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "x  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n"
          ]
        }
      ],
      "source": [
        "action = 0 # Move up\n",
        "a = env.step(action) # This is the function we use to interact with the environment\n",
        "env.render() # Renders the environment for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DalxfEmo-U6y",
        "outputId": "16c2bb52-8054-4c0b-a73f-88e1c2c0ec09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Action:  0\n",
            "Next state:  24\n",
            "Reward:  -1\n",
            "Done:  False\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "x  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n",
            "Action:  1\n",
            "Next state:  25\n",
            "Reward:  -1\n",
            "Done:  False\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  x  o  o  o  o  o  o  o  o  o  o\n",
            "o  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n",
            "Action:  2\n",
            "Next state:  36\n",
            "Reward:  -100\n",
            "Done:  False\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "x  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n",
            "Action:  3\n",
            "Next state:  36\n",
            "Reward:  -1\n",
            "Done:  False\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "x  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 0 -> UP, 1 -> RIGHT, 2 -> DOWN, 3 -> LEFT\n",
        "env.reset()\n",
        "import time\n",
        "for action in [0, 1, 2, 3]:\n",
        "    print(\"Action: \", action)\n",
        "    time.sleep(1)\n",
        "    next_state, reward, is_done, info = env.step(action)     # next_state, reward, is_done, info\n",
        "    print(\"Next state: \", next_state)\n",
        "    print(\"Reward: \", reward)\n",
        "    print(\"Done: \",is_done)\n",
        "    env.render()\n",
        "env.reset()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAL4YvAF-U6y"
      },
      "source": [
        "As you can see above, each non-terminal action has a reward of -1. 0 -> UP, 1 -> RIGHT, 2 -> DOWN, 3 -> LEFT. The moment the agent falls off the cliff the reward becomes -100 and the agent resets to the start."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "0BCsSRrH-U6y"
      },
      "outputs": [],
      "source": [
        "# Initialize values \n",
        "# num_episodes = 10000\n",
        "num_episodes = 1000\n",
        "lr = 0.1\n",
        "# epsilon = 1\n",
        "epsilon = 0.1\n",
        "max_steps_per_episode = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sy8_qjk-U6y",
        "outputId": "5641a7f3-4c1b-43af-a57a-153810c35246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]\n",
            " [0. 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "# Initialize Q function - a simplified version is used here \n",
        "# in reality the number of states may be unknown and all states may not be reachable \n",
        "\n",
        "# hint: use num_states as the key to a dictionary of lists\n",
        "Q = np.zeros((num_states, num_actions))\n",
        "\n",
        "print(Q)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WPKx8d8o-U6y"
      },
      "outputs": [],
      "source": [
        "def behavioral_policy(state, Q, num_actions, epsilon):\n",
        "    # Implement the epsilon-greedy policy\n",
        "    # Don't forget the epsilon-greedy idea\n",
        "    if random.uniform(0,1) > epsilon:\n",
        "        return np.argmax(Q[state,:])\n",
        "    # return random.choice(np.arange(env.action_space.n))\n",
        "    return random.choice(np.arange(num_actions))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5gsgwjy-U6y",
        "outputId": "1d597457-ca30-46e9-9fc0-6aa856faaa58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "1\n",
            "2\n",
            "1\n",
            "1\n",
            "3\n",
            "1\n",
            "2\n",
            "3\n"
          ]
        }
      ],
      "source": [
        "# You can use this to check if your algorithm is correct\n",
        "for i in range(10):\n",
        "    print(behavioral_policy(0, Q, num_actions, 0.8))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_M8EVue-U6z"
      },
      "source": [
        "### SARSA Learning "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "k4HhH0zf-U6z"
      },
      "outputs": [],
      "source": [
        "def sarsa(env, Q, num_actions, num_episodes, epsilon, lr):\n",
        "    # Given to students\n",
        "    episode_length = [0] * num_episodes\n",
        "    total_reward_episode = [0] * num_episodes\n",
        "    discount_rate = 1\n",
        "    \n",
        "\n",
        "    for episode in tqdm(range(num_episodes)):\n",
        "        state = env.reset()\n",
        "        is_done = False\n",
        "\n",
        "        # Implement SARSA\n",
        "        \n",
        "        while not is_done:\n",
        "\n",
        "            action = behavioral_policy(state, Q, num_actions, epsilon)\n",
        "            next_state, reward, is_done, info = env.step(action)\n",
        "            next_action = behavioral_policy(next_state, Q, num_actions, epsilon)\n",
        "            Q[state, action] = Q[state, action] + lr * ( reward + discount_rate * Q[ next_state, next_action ] - Q[ state, action ] )\n",
        "            state = next_state\n",
        "            episode_length[episode] += 1\n",
        "            total_reward_episode[episode] += reward\n",
        "    \n",
        "    # Write code here as well\n",
        "    # Hint: use np.argmax\n",
        "    policy = [\n",
        "        np.argmax(Q[state, :]) \\\n",
        "            for state in range(env.observation_space.n)\n",
        "    ]\n",
        "\n",
        "\n",
        "    return Q, policy, {\"rewards\": total_reward_episode, \"length\": episode_length}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "5Icyzo8v-U6z",
        "outputId": "84fcf06b-cfcb-456d-8c63-6e9ed8eec033"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 4819.38it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "GridWorld SARSA Optimal policy: \n",
            "\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 2]\n",
            " [0 0 3 1 1 0 1 1 1 1 1 2]\n",
            " [0 2 0 0 0 0 0 0 0 1 1 2]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Run SARSA\n",
        "optimal_sarsa_Q, sarsa_optimal_policy, sarsa_info = sarsa(env, Q, num_actions, num_episodes, epsilon, lr)\n",
        "print(\"\\nGridWorld SARSA Optimal policy: \\n\")\n",
        "print(np.array(sarsa_optimal_policy).reshape((4, 12)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7ihApKW-U6z"
      },
      "source": [
        "### Q-Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "id": "ttAoHrTD-U6z"
      },
      "outputs": [],
      "source": [
        "num_episodes = 10000\n",
        "lr = 0.2\n",
        "epsilon = 1\n",
        "max_steps_per_episode = 100\n",
        "\n",
        "def q_learning(env, Q, num_actions, num_episodes, epsilon, lr):\n",
        "    # Given to students\n",
        "    episode_length = [0] * num_episodes\n",
        "    total_reward_episode = [0] * num_episodes\n",
        "    discount_rate = 0.99\n",
        "    exploration_rate = 1\n",
        "\n",
        "    for episode in tqdm(range(num_episodes)):\n",
        "        state = env.reset()\n",
        "        is_done = False\n",
        "        # Implemnt Q-Learning\n",
        "\n",
        "        \n",
        "        while not is_done and episode_length[episode] < max_steps_per_episode and total_reward_episode[episode] > -100:\n",
        "            action = behavioral_policy(state, Q, num_actions, epsilon)\n",
        "            \n",
        "            new_state, reward, is_done, info = env.step(action)\n",
        "\n",
        "            Q[state, action] = Q[state, action] * (1 - lr) + lr * (reward + discount_rate * np.max(Q[new_state, :]))\n",
        "            state = new_state\n",
        "            total_reward_episode[episode] += reward\n",
        "            episode_length[episode] += 1\n",
        "        \n",
        "        epsilon = 0.01 + (1 - 0.01)*np.exp(-0.1*episode_length[episode])\n",
        "            \n",
        "    policy = [np.argmax(Q[key,:]) for key in range(num_states)]\n",
        "    # Write the code here\n",
        "\n",
        "    return Q, policy, {\"rewards\": total_reward_episode, \"length\": episode_length}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlr7cdEr-U6z",
        "outputId": "cfb98df5-7c45-4b16-c589-9c589a85ddcf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:40<00:00, 2482.82it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "GridWorld Q-Learning Optimal policy: \n",
            " [[ -13.99416454  -13.12541872  -13.12541872  -13.99416454]\n",
            " [ -13.12541872  -12.2478977   -12.2478977   -13.99416454]\n",
            " [ -12.2478977   -11.36151283  -11.36151283  -13.12541872]\n",
            " [ -11.36151283  -10.46617457  -10.46617457  -12.2478977 ]\n",
            " [ -10.46617457   -9.5617925    -9.5617925   -11.36151283]\n",
            " [  -9.5617925    -8.64827525   -8.64827525  -10.46617457]\n",
            " [  -8.64827525   -7.72553056   -7.72553056   -9.5617925 ]\n",
            " [  -7.72553056   -6.79346521   -6.79346521   -8.64827525]\n",
            " [  -6.79346521   -5.85198506   -5.85198506   -7.72553056]\n",
            " [  -5.85198506   -4.90099501   -4.90099501   -6.79346521]\n",
            " [  -4.90099501   -3.940399     -3.940399     -5.85198506]\n",
            " [  -3.940399     -3.940399     -2.9701       -4.90099501]\n",
            " [ -13.99416454  -12.2478977   -12.2478977   -13.12541872]\n",
            " [ -13.12541872  -11.36151283  -11.36151283  -13.12541872]\n",
            " [ -12.2478977   -10.46617457  -10.46617457  -12.2478977 ]\n",
            " [ -11.36151283   -9.5617925    -9.5617925   -11.36151283]\n",
            " [ -10.46617457   -8.64827525   -8.64827525  -10.46617457]\n",
            " [  -9.5617925    -7.72553056   -7.72553056   -9.5617925 ]\n",
            " [  -8.64827525   -6.79346521   -6.79346521   -8.64827525]\n",
            " [  -7.72553056   -5.85198506   -5.85198506   -7.72553056]\n",
            " [  -6.79346521   -4.90099501   -4.90099501   -6.79346521]\n",
            " [  -5.85198506   -3.940399     -3.940399     -5.85198506]\n",
            " [  -4.90099501   -2.9701       -2.9701       -4.90099501]\n",
            " [  -3.940399     -2.9701       -1.99         -3.940399  ]\n",
            " [ -13.12541872  -11.36151283  -13.12541872  -12.2478977 ]\n",
            " [ -12.2478977   -10.46617457 -112.12541872  -12.2478977 ]\n",
            " [ -11.36151283   -9.5617925  -112.12541872  -11.36151283]\n",
            " [ -10.46617457   -8.64827525 -112.12541872  -10.46617457]\n",
            " [  -9.5617925    -7.72553056 -112.12541872   -9.5617925 ]\n",
            " [  -8.64827525   -6.79346521 -112.12541872   -8.64827525]\n",
            " [  -7.72553056   -5.85198506 -112.12541872   -7.72553056]\n",
            " [  -6.79346521   -4.90099501 -112.12541872   -6.79346521]\n",
            " [  -5.85198506   -3.940399   -112.12541872   -5.85198506]\n",
            " [  -4.90099501   -2.9701     -112.12541872   -4.90099501]\n",
            " [  -3.940399     -1.99       -112.12541872   -3.940399  ]\n",
            " [  -2.9701       -1.99         -1.           -2.9701    ]\n",
            " [ -12.2478977  -112.12541872  -13.12541872  -13.12541872]\n",
            " [   0.            0.            0.            0.        ]\n",
            " [   0.            0.            0.            0.        ]\n",
            " [   0.            0.            0.            0.        ]\n",
            " [   0.            0.            0.            0.        ]\n",
            " [   0.            0.            0.            0.        ]\n",
            " [   0.            0.            0.            0.        ]\n",
            " [   0.            0.            0.            0.        ]\n",
            " [   0.            0.            0.            0.        ]\n",
            " [   0.            0.            0.            0.        ]\n",
            " [   0.            0.            0.            0.        ]\n",
            " [   0.            0.            0.            0.        ]]\n",
            "\n",
            "Estimated Optimal Policy (UP = 0, RIGHT = 1, DOWN = 2, LEFT = 3, N/A = -1):\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 2]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 2]\n",
            " [1 1 1 1 1 1 1 1 1 1 1 2]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Run Q-Learning \n",
        "optimal_Q, q_optimal_policy, q_info = q_learning(env, Q, num_actions, num_episodes, epsilon, lr)\n",
        "print(\"\\nGridWorld Q-Learning Optimal policy: \\n\", optimal_Q)\n",
        "\n",
        "\n",
        "print(\"\\nEstimated Optimal Policy (UP = 0, RIGHT = 1, DOWN = 2, LEFT = 3, N/A = -1):\")\n",
        "print(np.array(q_optimal_policy).reshape((4,12)))\n",
        "\n",
        "\n",
        "rewards_per_thousand_episodes = np.split(np.array(q_info[\"rewards\"]),num_episodes/100)\n",
        "count = 100\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 269,
      "metadata": {
        "id": "MPG64gMe-U6z"
      },
      "outputs": [],
      "source": [
        "# run this cell if you do not have the matplotlib library\n",
        "# !pip install matplotlib\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {
        "id": "81Km5lRY-U6z"
      },
      "outputs": [],
      "source": [
        "def plot_rate(episode_length, total_reward_episode, title):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
        "    ax[0].plot(episode_length)\n",
        "    ax[0].set_title(\"Episode Length over time\")\n",
        "    ax[0].set(xlabel=\"Episode\", ylabel=\"Length\")\n",
        "    ax[1].plot(total_reward_episode)\n",
        "    ax[1].set_title(\"Episode reward over time\")\n",
        "    ax[1].set(xlabel=\"Episode reward over time\", ylabel=\"Reward\")\n",
        "    fig.suptitle(title)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "bJgIKRvl-U6z",
        "outputId": "1ebf1426-42bc-4b1b-9ae0-c559ad126d0b"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "#plot_rate(sarsa_info[\"length\"], sarsa_info[\"rewards\"], \"GridWorld: SARSA\")\n",
        "plot_rate(q_info[\"length\"], q_info[\"rewards\"], \"GridWorld: Q-Learning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy5mooah-U6z"
      },
      "source": [
        "## Task 1b: Learning in Windy Grid world"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqTbJl04-U6z"
      },
      "source": [
        "WindyGridWorld is similar to GridWorld, but with a few differences. You only need to move to the target state. But this time there is a cross-wind across the center of the grid that will push you upwards. In columns 3, 4, 5, and 8 there are winds of strength 1 while in column 6 and 7 there are winds of strength 2. For more details refer Example 6.5 in\n",
        "\n",
        " http://incompleteideas.net/book/RLbook2020.pdf\n",
        "\n",
        " You only need to change the environment and reuse the SARSA and Q-learning algorithms. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "EcAWoVybW_vB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "from gym.envs.toy_text import discrete\n",
        "\n",
        "UP, RIGHT, DOWN, LEFT = range(4)\n",
        "\n",
        "\n",
        "class WindyGridWorld(discrete.DiscreteEnv):\n",
        "    def __init__(self):\n",
        "        self.shape = (7, 10)\n",
        "        nS = self.shape[0] * self.shape[1]\n",
        "        nA = 4\n",
        "        winds = np.zeros(self.shape)\n",
        "        winds[:, [3,4,5, 8]] = 1\n",
        "        winds[:, [6, 7]] = 2\n",
        "        self.goal = (3, 7)\n",
        "        # Transition probability calculation from GridWorld\n",
        "        P = {}\n",
        "        for s in range(nS):\n",
        "            position = np.unravel_index(s, self.shape)\n",
        "            P[s] = {a: [] for a in range(nA)}\n",
        "            P[s][UP] = self._calculate_transition_prob(position, [-1, 0], winds)            \n",
        "            P[s][DOWN] = self._calculate_transition_prob(position, [1, 0], winds)            \n",
        "            P[s][LEFT] = self._calculate_transition_prob(position, [0, -1], winds)            \n",
        "            P[s][RIGHT] = self._calculate_transition_prob(position, [0, 1], winds)\n",
        "        # Starting position (3, 0)\n",
        "        initial_s = np.zeros(nS)\n",
        "        initial_s[np.ravel_multi_index((3,0), self.shape)] = 1.0\n",
        "        super(WindyGridWorld, self).__init__(nS, nA, P, initial_s)\n",
        "\n",
        "    def _calculate_transition_prob(self, current, move, winds):\n",
        "        # Transition probability for a position landed on is 1.0, new_state calculated\n",
        "        new_position = np.array(current) + np.array(move) + np.array([-1, 0]) * winds[(tuple(current))]\n",
        "        new_position = self._limit_coordinates(new_position).astype(int)\n",
        "        new_state = np.ravel_multi_index(tuple(new_position), self.shape)\n",
        "        is_done = tuple(new_position) == self.goal\n",
        "        return [(1.0, new_state, -1, is_done)]\n",
        "\n",
        "    def _limit_coordinates(self, coord):\n",
        "        for i in range(2):\n",
        "            coord[i] = min(coord[i], self.shape[i] - 1)\n",
        "            coord[i] = max(0, coord[i])\n",
        "        return coord\n",
        "\n",
        "    def render(self):\n",
        "        outfile = sys.stdout\n",
        "        for s in range(self.nS):\n",
        "            position = np.unravel_index(s, self.shape)\n",
        "            if self.s == s:\n",
        "                output = \" x \"\n",
        "            elif position == self.goal:\n",
        "                output = \" T \"\n",
        "            else:\n",
        "                output = \" o \"\n",
        "            if position[1] == 0:\n",
        "                output = output.lstrip()\n",
        "            if position[1] == self.shape[1] - 1:\n",
        "                output = output.rstrip()\n",
        "                output += \"\\n\"\n",
        "            outfile.write(output)\n",
        "        outfile.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUCXL-gk-U60",
        "outputId": "310f0bde-d520-4f0f-b815-a66739c4be4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o\n",
            "x  o  o  o  o  o  o  T  o  o\n",
            "o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Windy Grid World environment\n",
        "env = WindyGridWorld()\n",
        "env.reset()\n",
        "env.render()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcvSpYzl-U60",
        "outputId": "d62e5998-5e36-4c68-e78d-277424e4e2fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of actions:  4\n",
            "Number of states:  70\n"
          ]
        }
      ],
      "source": [
        "num_actions = env.action_space.n \n",
        "num_states = env.observation_space.n \n",
        "\n",
        "print(\"Number of actions: \", num_actions)\n",
        "print(\"Number of states: \", num_states)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9spUFI_a-U60"
      },
      "source": [
        "Play around with different learning rates epsilons, and Q initializations to see what is best."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "id": "0cwHcpwq-U60"
      },
      "outputs": [],
      "source": [
        "num_episodes = 10000\n",
        "lr = 0.01\n",
        "epsilon = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "id": "NTDrGMlz-U60"
      },
      "outputs": [],
      "source": [
        "# Initialize Q function - a simplified version is used here \n",
        "# in reality the number of states may be unknown and all states may not be reachable \n",
        "\n",
        "# hint: use num_states as the key to a dictionary of lists\n",
        "Q = np.zeros((num_states, num_actions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "VhORioCy-U60",
        "outputId": "53aca886-7cd8-4978-8bfe-58a3c4f38f5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/10000 [00:04<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-218-47319df394c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimal_sarsa_Q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msarsa_optimal_policy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msarsa_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msarsa\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_episodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n WindyGridWorld SARSA Optimal policy: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msarsa_optimal_policy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-102-17144019bb9b>\u001b[0m in \u001b[0;36msarsa\u001b[0;34m(env, Q, num_actions, num_episodes, epsilon, lr)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mepisode_length\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mtotal_reward_episode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mpolicy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# Write code here as well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "optimal_sarsa_Q, sarsa_optimal_policy, sarsa_info = sarsa(env, Q, num_actions, num_episodes, epsilon, lr)\n",
        "print(\"\\n WindyGridWorld SARSA Optimal policy: \\n\", sarsa_optimal_policy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1OIhN6h-U60",
        "outputId": "9b102e74-1eba-47a0-f690-3969e6ddad4f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:57<00:00, 1754.17it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Estimated Optimal Policy (UP = 0, RIGHT = 1, DOWN = 2, LEFT = 3, N/A = -1):\n",
            "\n",
            " WindyGridWorld Q-Learning Optimal policy: \n",
            " [[1 1 1 1 1 1 1 1 1 2]\n",
            " [1 1 1 1 1 1 1 1 1 2]\n",
            " [1 1 1 1 1 1 1 1 1 2]\n",
            " [1 1 1 1 1 1 1 0 1 2]\n",
            " [1 1 1 1 1 1 0 2 3 3]\n",
            " [1 1 1 1 1 0 0 2 3 0]\n",
            " [1 1 1 1 0 0 0 0 0 3]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "optimal_Q, q_optimal_policy, q_info = q_learning(env, Q, num_actions, num_episodes, epsilon, lr)\n",
        "print(\"\\nEstimated Optimal Policy (UP = 0, RIGHT = 1, DOWN = 2, LEFT = 3, N/A = -1):\")\n",
        "q_optimal_policy = np.array(q_optimal_policy).reshape((7,10))\n",
        "print(\"\\n WindyGridWorld Q-Learning Optimal policy: \\n\", q_optimal_policy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8I_ef80-U60"
      },
      "outputs": [],
      "source": [
        "plot_rate(sarsa_info[\"length\"], sarsa_info[\"rewards\"], \"GridWorld: SARSA\")\n",
        "plot_rate(q_info[\"length\"], q_info[\"rewards\"], \"GridWorld: Q-Learning\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLc1fVhM-U60"
      },
      "source": [
        "# Task 2: Analysis (Comparison of Q-learning and SARSA learning algorithms)\n",
        "\n",
        "1. Comment on the number of episodes required to converge to the optimal policy for both environments. \n",
        "       \n",
        "2. Discuss the differences in the reward graphs.  \n",
        "\n",
        "3. Calculate the average return across the episodes for each environment. It gives a measure of the performance of the algorithm while learning (i.e., online performance).  \n",
        "\n",
        "4. Calculate the return after convergence. It gives you a measure of the performance after the learning is completed (i.e., offline performance). \n",
        "\n",
        "5. Briefly summarize your results.\n",
        " \n",
        " It is advisable to rerun the algorithm a few times to get a clearer understanding of the algorithms."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.13 ('IT5005')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d865cb9cdb183744776ff4f65272db74d2b266e002a2823cb7151ebc57ef5d13"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
